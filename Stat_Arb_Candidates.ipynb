{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/numberjuani/cryptocoint/blob/master/Stat_Arb_Candidates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WmpHBk2A27f"
      },
      "source": [
        "The objective of this notebook is to identify crypto currencies that are suitable for statistical arbitrage.\n",
        "In order to come up with an objective ranking, we will test all pairs for correlation and cointegration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ5b3flAA27g"
      },
      "outputs": [],
      "source": [
        "#!pip3 install binance-connector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSIvqlU9A27h"
      },
      "outputs": [],
      "source": [
        "from statsmodels.api import OLS\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from binance.spot import Spot as SpotClient\n",
        "import pandas as pd\n",
        "from joblib import Parallel, delayed\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the function we will use to calculate wether a pair is cointegrated at a certain point in time, even though it returns a boolean,\n",
        "We can later sum these bools as 0 - 1 to see which crypto are cointegrated most. This is necessary to prevent lookahead bias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjGsZiQoA27h"
      },
      "outputs": [],
      "source": [
        "def is_cointegrated(x, y):\n",
        "    result = OLS(x, y).fit()\n",
        "    hedge_ratio = result.params[0]\n",
        "    adf_results = adfuller(result.resid)    \n",
        "    if adf_results[0] <= adf_results[4]['10%'] and adf_results[1] <= 0.1:\n",
        "        return (True,hedge_ratio)\n",
        "    else:\n",
        "        return (False,hedge_ratio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A simple wrapper function to convert the data provided by the binance API to a pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzWy5JiFA27h"
      },
      "outputs": [],
      "source": [
        "def api_reponse_to_pandas(ohlc_dict: dict,symbol:str):\n",
        "    df = pd.DataFrame(ohlc_dict,columns=['open_time', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_asset_volume', 'num_trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'])\n",
        "    df['close_time'] = pd.to_datetime(df['close_time'], unit='ms', utc=True)\n",
        "    #check if there are is daylight savings time change\n",
        "    df['close'] = df['close'].astype(float)\n",
        "    df.set_index('close_time', inplace=True)\n",
        "    df = df[['close']]\n",
        "    return (symbol,df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function checks if the pair is cointegrated, calculates the rolling correlation ,and outputs summary statistics that can be used to compare pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hICTmY6iA27h"
      },
      "outputs": [],
      "source": [
        "def check_coins(coin_1_name:str,coin_1_data:pd.DataFrame,coin_2_name:str,coin_2_data:pd.DataFrame,rolling_window:int):\n",
        "    both = pd.merge(coin_1_data, coin_2_data, how='inner', left_index=True, right_index=True,suffixes=('_1','_2'))\n",
        "    both['rolling_corr'] = both['close_1'].rolling(window=rolling_window).corr(both['close_2'])\n",
        "    both.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    #print(both.isna().sum())\n",
        "    both.reset_index(inplace=True)\n",
        "    both['rolling_cointegration'] = False\n",
        "    both['hedge_ratio'] = 0\n",
        "    both['spread'] = both['close_1'] - both['close_2']\n",
        "    if len(both) > rolling_window+1:\n",
        "        for index in both.index:\n",
        "            if index > rolling_window:\n",
        "                cointegration,hedge_ratio = is_cointegrated(both.loc[index-rolling_window:index,'close_1'],both.loc[index-rolling_window:index,'close_2'])\n",
        "                both.loc[index,'hedge_ratio'] = hedge_ratio\n",
        "                if cointegration:\n",
        "                    both.loc[index,'rolling_cointegration'] = True\n",
        "        #now we save the corr abd cointegration data to be compared with all the other coins\n",
        "        corr_mean = both['rolling_corr'].mean()\n",
        "        coint_mean = both['rolling_cointegration'].mean()\n",
        "        pair = coin_1_name + '_' + coin_2_name\n",
        "        spread_mean = both['spread'].mean()\n",
        "        spread_std = both['spread'].std()\n",
        "        hedge_ratio_last = both['hedge_ratio'].iloc[-1]\n",
        "        return {'pair':pair,'corr_mean':corr_mean,'coint_mean':coint_mean,'both':corr_mean*coint_mean,'spread_mean':spread_mean,'spread_std':spread_std,'hedge_ratio_last':hedge_ratio_last}\n",
        "    else:\n",
        "        return {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpdSEUKpA27i"
      },
      "outputs": [],
      "source": [
        "spot_client = SpotClient()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H46YEWVZA27i"
      },
      "outputs": [],
      "source": [
        "spot_info = pd.DataFrame(spot_client.exchange_info()['symbols'])\n",
        "#for the sake of simplicity in this exercise we will only consider coins with USDT stablecoin in the quote asset. \n",
        "#Also, we will only consider coins that can be shorted since we will need to buy/short both coins on the pair\n",
        "quotes_to_consider = ['USDT']\n",
        "spot_info = spot_info[(spot_info.quoteAsset.isin(quotes_to_consider)) & (spot_info.status == 'TRADING')& (spot_info.isMarginTradingAllowed)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbDV5-PgA27j"
      },
      "outputs": [],
      "source": [
        "f'Considering {len(spot_info)} coins for pairs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmbI_mByA27j"
      },
      "outputs": [],
      "source": [
        "symbols:list[str] = spot_info.symbol.tolist()\n",
        "pairs = []\n",
        "#here we create a list of pairs, making sure that were not repeating combinations or using the same symbol twice\n",
        "for x in range(0,len(symbols)-1):\n",
        "    for y in range(len(symbols)-1,0,-1):\n",
        "        if symbols[x] != symbols[y]:\n",
        "            pair = [symbols[x],symbols[y]]\n",
        "            reverse_pair = [symbols[y],symbols[x]]\n",
        "            if pair not in pairs and reverse_pair not in pairs:\n",
        "                pairs.append(pair)\n",
        "f'A total of {len(pairs)} distinct pairs are possible'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MeE3p22A27j"
      },
      "source": [
        "Now we can proceed to request OHLCV data for the coins we have identified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMy7kkcJA27j"
      },
      "outputs": [],
      "source": [
        "coins_data:list[tuple[str,pd.DataFrame]] = (Parallel(n_jobs=-1)(delayed(api_reponse_to_pandas)(spot_client.klines(symbol=sym, interval='5m',limit=1000),sym) for sym in symbols))\n",
        "#now we transfrom the list of tuples to a dictionary to its easy to work with\n",
        "coins_data:dict[str,pd.DataFrame] = dict(coins_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testing all possible pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtFl4fMWA27k"
      },
      "outputs": [],
      "source": [
        "results = (Parallel(n_jobs=-1)(delayed(check_coins)(pair[0],coins_data[pair[0]],pair[1],coins_data[pair[1]],500) for pair in pairs))\n",
        "#remove all {} from the results\n",
        "results = [x for x in results if x != {}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHOZYrJ0A27k"
      },
      "outputs": [],
      "source": [
        "results_frame = pd.DataFrame(results)\n",
        "results_frame.sort_values(by=['both'],ascending=False,inplace=True)\n",
        "results_frame"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "Stat Arb Candidates.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "d158ff5a88e3e59b7bb4d4d7e0c618158e1ebf06cdbb0fab67daed76464a2af1"
    },
    "kernelspec": {
      "display_name": "Python 3.10.3 ('.cointvenv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
